{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook explains the theory behind microbial sourcetracking using a Gibb's sampler. \n",
    "\n",
    "## The theory and examples are based on work detailed in [Knights et al. 2011](http://www.nature.com/nmeth/journal/v8/n9/abs/nmeth.1650.html): if you find this work helpful please consider citing Dan Knights paper.\n",
    "\n",
    "\n",
    "#### Note:\n",
    "The formula for calculating the probability that a held-out sequence will be assigned to a given environment is reported incorrectly in [Knights et al. 2011](http://www.nature.com/nmeth/journal/v8/n9/abs/nmeth.1650.html). The corrected formula is:\n",
    "\n",
    "$$P( z_{i} = v \\mid  z^{ \\neg i}, x)  \\propto P(x_{i} \\mid v)  \\times P(v \\mid x^{ \\neg i}) = \\begin{cases}\n",
    "\\frac{m_{x_{i}v} + \\alpha_{1}}{m_{v} + \\tau \\alpha_{1}} \\times \\frac{n_{v}^{ \\neg i} + \\beta}{n - 1 + \\beta V} & v < V\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{m_{x_{i}v} + n \\alpha_{2}}{m_{v} + \\tau n \\alpha_{2}} \\times \\frac{n_{v}^{ \\neg i} + \\beta}{n - 1 + \\beta V} & v = V\n",
    "\\end{cases}$$\n",
    "\n",
    "This updated formula is what is truly being calculated by both the [R sourcetracking algorithm](https://github.com/danknights/sourcetracker) and this repository (personal communication with Dan Knights).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Given a number of `sources`, determine the contribution of each `source` to a `sink`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gibb's sampler works in four basic steps:\n",
    "    1. Randomly assign the sequences in a sink to source environments. These random assignments represent which source a given sink sequence came from.\n",
    "    2. Select one of the sequences from step 1, calculate the *actual* probabilities of that sequence having come from any of the source environments, and update the assigned source environment of the sequence based on a random draw with the calculated probabilities. Repeat many times. \n",
    "    3. At intervals in the repeats of step 2, take the source environment assingments of all the sequences in a sink and record them. \n",
    "    4. After doing step 3 a certain number of times (i.e. recording the full assignments of source environments for each sink sequence), terminate the iteration and move to the next sink.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machinery\n",
    "There are two probabilities that form the basis of the Gibb's calculation, namely:\n",
    "\n",
    "$P(t \\mid v)$ = probability of a source emitting a sequence from a specific taxon\n",
    "\n",
    "$P(v)$ = probability of a sequence having come from a given source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## $P(t \\mid v)$\n",
    "$P(t \\mid v)$, referenced in the code as `p_tv`, is the probability of a source emitting a sequence from a specific taxon. Said another way, this is the probability of seeing a sequence from taxon $t$ being produced from source $v$. Let's look at an example table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1  F2   F3\n",
       "Source1   0  10  100\n",
       "Source2   3   6    9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(data=[[0, 10, 100], [3, 6, 9]], \n",
    "                     columns=['F1', 'F2', 'F3'], \n",
    "                     index=['Source1', 'Source2'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that the above table represents a pair of urns (`Source1` and `Source2`) and that each urn has 3 colors of billiard in it (colors `F1` through `F`). Now, lets say you close your eyes, and randomly select an urn, say `Source2`. You reach in to that urn and withdraw a random billiard. What is the probability that you have selected a billiard of color `F1`? \n",
    "\n",
    "We can make this conditional probability calculation very simply by dividing each Feature count within a source by the total sequences seen in that Source. This would also be the relative abundance for each Source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1        F2        F3\n",
       "Source1  0.000000  0.090909  0.909091\n",
       "Source2  0.166667  0.333333  0.500000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum each OTU\n",
    "table = table.apply(lambda row: row / row.sum(), axis=1)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the $P(t \\mid v)$. Let's imagine that we saw `F1` in our Sink. What is the probability that `F1` came from either `Source1` or `Source2`? Well, from the table above we can see that `F1` was not seen in `Source1`. Therefore, we update the table by dividing by each column sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.354839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1        F2        F3\n",
       "Source1  0.0  0.214286  0.645161\n",
       "Source2  1.0  0.785714  0.354839"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probability (p_tv) for each OTU\n",
    "table_p_tv = table.loc[['Source1', 'Source2']].div(table.sum(axis=0), axis=1)\n",
    "table_p_tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows $P(t \\mid v)$ for each $t, v$ (i.e each OTU and Source). \n",
    "\n",
    "To check our understanding, we can think about the values in this matrix. If we see `F1` in the sink sample, it could only have come from `Source2`, and therefore the p_tv (the probability of seeing `F1`) for `Source2` is 100%. If `F3` was seen in our sink, there would be a 91.7% chance of it coming from `Source1` and a 8.3% chance of it coming from `Source2`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation for `p_tv` is really about this simple. We add a few tuning parameters to this calculation to ensure that more of the probability space is explored. In the biologial context, our idea is that because we sequence only a small fraction of the source environment, we are likely to miss some sources of some taxa. The parameters described below help us correct for this.\n",
    "\n",
    "**Alpha1**\n",
    "\n",
    "You may note above that OTU1's abundance in Source1 is 0, and therefore no probability can be provided for that OTU to that Source. SourceTracker2 therefore allows the user to specify an `alpha1` value on the command line, which is the prior counts to be added to all of the sample counts. This would therefore provide a small amount of probability to OTU1 in Source1, and the table would look like (assuming an alpha1 of 0.01):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>100.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>3.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1    F2     F3\n",
       "Source1  0.1  10.1  100.1\n",
       "Source2  3.1   6.1    9.1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(data=[[0.1, 10.1, 100.1], [3.1, 6.1, 9.1]], \n",
    "                     columns=['F1', 'F2', 'F3'], \n",
    "                     index=['Source1', 'Source2'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Unknown ** and **Alpha2**\n",
    "\n",
    "A key feature of SourceTracker2 is to create an Unknown source environment. The basic premise here is to identify sequences that don't have a high probability of being derived from the known and specified Source Environments. An Unknown community is propogated with sequences with the `alpha2` parameter that specifies what percent of the total sink sequence count to be added for each OTU in the Unknown. For example, a sink with 100 sequences and an alpha of 0.001 would add `100 * 0.001 = 0.1` counts to each OTU, and the table would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>100.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>3.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1    F2     F3\n",
       "Source1  0.1  10.1  100.1\n",
       "Source2  3.1   6.1    9.1\n",
       "Unknown  0.1   0.1    0.1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(data=[[0.1, 10.1, 100.1], [3.1, 6.1, 9.1], [0.1, 0.1, 0.1]], \n",
    "                     columns=['F1', 'F2', 'F3'], \n",
    "                     index=['Source1', 'Source2', 'Unknown'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OTU1</th>\n",
       "      <th>OTU2</th>\n",
       "      <th>OTU3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.619632</td>\n",
       "      <td>0.915828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.374233</td>\n",
       "      <td>0.083257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             OTU1      OTU2      OTU3\n",
       "Source1  0.030303  0.619632  0.915828\n",
       "Source2  0.939394  0.374233  0.083257"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(data=[[0.1, 10.1, 100.1], [3.1, 6.1, 9.1], [0.1, 0.1, 0.1]], \n",
    "                     columns=['OTU1', 'OTU2', 'OTU3'], \n",
    "                     index=['Source1', 'Source2', 'Unknown'])\n",
    "table_p_tv = table.loc[['Source1', 'Source2']].div(table.sum(axis=0), axis=1)\n",
    "table_p_tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the precalculated p_tv values we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $P(v)$\n",
    "\n",
    "The second probability that the Gibb's sampler must calculate is $P(v)$, the probability that a sequence came from a given source. In the code, we refer to this value as `p_v`. In the interal loops of the Gibb's function, we randomly assign sequences from a sink to having come from a given source. Iteratively, we remove one of each of these sequences (one at a time) and reassign the origin of that sequence to an environment. `p_v` is the probability that one of these held out sequences came from any one of the environments.\n",
    "\n",
    "We'll walk through an example below.Each sink sample can be thought of a collection of sequences that identify a taxa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sink_otus = [1, 1, 1, 2, 2, 2, 2, 2, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sink sample contains 10 sequences that each are assigned to one of the Fs in our table. Let's forget for a moment that each Feature has a certain probability of being found in a given source environment (the `p_tv`), and instead focus on the number of possible Source environments we have. If our sink sample was completely unidentified with Featre information, it would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = ['X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we only knew that we had 3 source environments that each sink sequence must have come from, then we would say that each sink sequence had a `1/3` probability of being assigned to each source. \n",
    "\n",
    "Let's randomly assign each sink sequence to a source environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sink_source = [3, 1, 2, 3, 2, 3, 3, 1, 2, 1]\n",
    "# where 1 = Source1, 2 = Source2, and 3 = Unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate our `p_v`, we count the number of sequences assigned to each environment and divide by the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3  0.3  0.4]\n"
     ]
    }
   ],
   "source": [
    "p_v = np.bincount(sink_source, minlength=3)[1:]/float(len(sink_source))\n",
    "print(p_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the internal loops of the Gibb's function, we'll end up withdrawing a sequence from the `sink_source` vector, and then re-calculating the `p_v`. For example, lets say we are on the 5th iteration, so we withdraw the 5th sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3  0.2  0.4]\n"
     ]
    }
   ],
   "source": [
    "sink_source_copy = sink_source[:]\n",
    "env_of_fifth_sequence = sink_source_copy.pop(4)\n",
    "# recalculate p_v\n",
    "p_v = np.bincount(sink_source_copy, minlength=3)[1:]/float(len(sink_source))\n",
    "print(p_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are calculating $P(v \\mid x^{ \\neg i})$ in the overall SourceTracker2 formula (seen in the first cell). In the actual code, `p_v` is multiplied by `p_tv` to create a new probability vector for identifying where the sequence that was withdrawn actually came from.\n",
    "\n",
    "As with `p_tv` there are tuning parameters that we add to make the model explore a larger portion of probability space. \n",
    "\n",
    "**Beta**\n",
    "\n",
    "Beta is added to the count of each environment, to prevent an environment from having zero probability mass. In many ways it is like **alpha1** which we add to the source matrix data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restarts** \n",
    "\n",
    "When we restart the gibbs sampler, we reshuffle the assignments of each sink sequence to a Source Environment, and begin our calculations again, essentially redoing all the steps above. This is done to allow the proportions to converge in an independent Markov Chain. Since there is high correlation between adjacent states in the Markov chain, the `restarts` and `delay` parameters of SourceTracker2 are used to avoid correlated answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sink_otus = [1, 1, 1, 2, 2, 2, 2, 2, 2, 3]\n",
    "sink_otus_positions_shuffled = [4, 1, 8, 2, 7, 9, 0, 3, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we do is create a shuffled order for which to walk through our sink sequences. The above says that the first sequence we want to predict the source environment contributor for is the `4` index, which relates to `F2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61836744,  0.37346926,  0.00816331])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For OTU2, taken from the table above\n",
    "# for Source1, Source2, Unknown\n",
    "p_tv = np.array([0.619632, 0.374233, 0.006135])\n",
    "p_v = np.array([0.3, 0.3, 0.4])\n",
    "\n",
    "combined_probability = p_tv * p_v\n",
    "combined_probability / combined_probability.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now calculated the probability that this sink sequence at index 4 should belong to each Source Environment and the Unknown. We can then randomly assign that sequence to one of the environments given those probability distributions. We also update our p_v by adding 1 to the selected source community.\n",
    "\n",
    "**IF** the sequence gets assigned to the Unknown community, then the Unknown community gets an extra count in the table. In this way, the Unknown community gets propogated through repeated iterations. No changes are made to the table if the sequence gets assigned to an identified source (Source1 or Source2).\n",
    "\n",
    "Let's assume the unlikely case that our sample _did_ get assigned to the Unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>100.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>3.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F1    F2     F3\n",
       "Source1  0.1  10.1  100.1\n",
       "Source2  3.1   6.1    9.1\n",
       "Unknown  0.1   1.1    0.1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the table with the OTU2 count\n",
    "table = pd.DataFrame(data=[[0.1, 10.1, 100.1], [3.1, 6.1, 9.1], [0.1, 1.1, 0.1]], \n",
    "                     columns=['F1', 'F2', 'F3'], \n",
    "                     index=['Source1', 'Source2', 'Unknown'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Source1</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.583815</td>\n",
       "      <td>0.915828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source2</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.352601</td>\n",
       "      <td>0.083257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1        F2        F3\n",
       "Source1  0.030303  0.583815  0.915828\n",
       "Source2  0.939394  0.352601  0.083257"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and recalculate the p_tv values\n",
    "table_p_tv = table.loc[['Source1', 'Source2']].div(table.sum(axis=0), axis=1)\n",
    "table_p_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 2: 2, 3: 5})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the p_v values\n",
    "# change the 4th index to community 3\n",
    "sink_source = [3, 1, 2, 3, 3, 3, 3, 1, 2, 1]\n",
    "Counter(sink_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sink_otus = [1, 1, 1, 2, 2, 2, 2, 2, 2, 3]\n",
    "sink_otus_positions_shuffled = [4, 1, 8, 2, 7, 9, 0, 3, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd move on to index position 1, and repeat the entire process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After so many iterations, or **burn ins**, we can start to record the p_v source environment counts as the percent contribution of each Source to our sink sample. The **delay** determines how many iterations to skip between draws after the burnin period. The **draws_per_restart** indicate how many draws to save from each restart. All draws are then averaged together to provide a final mixing proportion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
